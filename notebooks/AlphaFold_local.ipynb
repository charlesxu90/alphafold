{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_UNIFIED_MEMORY'] = '1'\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '4.0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a dependency issue\n",
    "- stereo_chemical_props.txt\n",
    "- openmm.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -q -P content https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply OpenMM patch.\n",
    "# ! pushd content/site-packages/site-packages/ && patch -p0 < content/alphafold/docker/openmm.patch && popd\n",
    "# ! mkdir -p content/alphafold/alphafold/common\n",
    "# ! cp -f content/stereo_chemical_props.txt content/alphafold/alphafold/common\n",
    "# ! mkdir -p content/site-packages/alphafold/common/\n",
    "# ! cp -f content/stereo_chemical_props.txt content/site-packages/alphafold/common/\n",
    "\n",
    "import sys\n",
    "# sys.path.append('content/alphafold')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
    "SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_colab_2022-12-06.tar'\n",
    "PARAMS_DIR = './alphafold/data/params'\n",
    "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir --parents \"{PARAMS_DIR}\"\n",
    "# ! wget -O \"{PARAMS_PATH}\" \"{SOURCE_URL}\"\n",
    "# ! tar --extract --verbose --file=\"{PARAMS_PATH}\"  --directory=\"{PARAMS_DIR}\" --preserve-permissions\n",
    "# ! rm \"{PARAMS_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with NVIDIA A100-PCIE-40GB GPU\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "if jax.local_devices()[0].platform == 'tpu':\n",
    "  raise RuntimeError('Colab TPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
    "elif jax.local_devices()[0].platform == 'cpu':\n",
    "  raise RuntimeError('Colab CPU runtime not supported. Change it to GPU via Runtime -> Change Runtime Type -> Hardware accelerator -> GPU.')\n",
    "else:\n",
    "  print(f'Running with {jax.local_devices()[0].device_kind} GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the amino acid sequence(s) to fold.\n",
    "\n",
    "- If you enter only a single sequence, the monomer model will be used (unless you override this below).\n",
    "- If you enter multiple sequences, the multimer model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the multimer model with 3 sequences.\n"
     ]
    }
   ],
   "source": [
    "from alphafold.notebooks import notebook_utils\n",
    "import enum\n",
    "\n",
    "@enum.unique\n",
    "class ModelType(enum.Enum):\n",
    "  MONOMER = 0\n",
    "  MULTIMER = 1\n",
    "\n",
    "sequence_1 = 'ARNGDHCPLGPGRCCRLHTVRASLEDLGWADWVLSPREVQVTMCIGACPSQFRAANMHAQIKTSLHRLKPDTVPAPCCVPASYNPMVLIQKTDTGVSLQTYDDLLAKDCHCI'  #@param {type:\"string\"} antigen\n",
    "sequence_2 = 'QVQLVQSGAEVKKPGSSVKVSCKASGYTFSSYNIDWVRQAPGQGLEWMGGINPIFGTAFYNQKFQGRVTITADESTSTAYMELSSLRSEDTAVYYCAREAITTVGAMDHWGQGTLVTVSS'  #@param {type:\"string\"} antibody VH\n",
    "sequence_3 = 'EIVLTQSPATLSLSPGERATLSCRTSQSVHNYLAWYQQKPGQAPRLLIYDASTRADGIPARFSGSGSGTDFTLTISSLEPEDFAVYYCQQFWSWPWTFGQGTKVEIK'  #@param {type:\"string\"} antibody VL\n",
    "\n",
    "input_sequences = (sequence_1, sequence_2, sequence_3)\n",
    "\n",
    "MIN_PER_SEQUENCE_LENGTH = 16\n",
    "MAX_PER_SEQUENCE_LENGTH = 4000\n",
    "MAX_MONOMER_MODEL_LENGTH = 2500\n",
    "MAX_LENGTH = 4000\n",
    "MAX_VALIDATED_LENGTH = 3000\n",
    "\n",
    "use_multimer_model_for_monomers = False #@param {type:\"boolean\"}\n",
    "\n",
    "# Validate the input sequences.\n",
    "sequences = notebook_utils.clean_and_validate_input_sequences(\n",
    "    input_sequences=input_sequences,\n",
    "    min_sequence_length=MIN_PER_SEQUENCE_LENGTH,\n",
    "    max_sequence_length=MAX_PER_SEQUENCE_LENGTH)\n",
    "\n",
    "if len(sequences) == 1:\n",
    "  if use_multimer_model_for_monomers:\n",
    "    print('Using the multimer model for single-chain, as requested.')\n",
    "    model_type_to_use = ModelType.MULTIMER\n",
    "  else:\n",
    "    print('Using the single-chain model.')\n",
    "    model_type_to_use = ModelType.MONOMER\n",
    "else:\n",
    "  print(f'Using the multimer model with {len(sequences)} sequences.')\n",
    "  model_type_to_use = ModelType.MULTIMER\n",
    "\n",
    "# Check whether total length exceeds limit.\n",
    "total_sequence_length = sum([len(seq) for seq in sequences])\n",
    "if total_sequence_length > MAX_LENGTH:\n",
    "  raise ValueError('The total sequence length is too long: '\n",
    "                   f'{total_sequence_length}, while the maximum is '\n",
    "                   f'{MAX_LENGTH}.')\n",
    "\n",
    "# Check whether we exceed the monomer limit.\n",
    "if model_type_to_use == ModelType.MONOMER:\n",
    "  if len(sequences[0]) > MAX_MONOMER_MODEL_LENGTH:\n",
    "    raise ValueError(\n",
    "        f'Input sequence is too long: {len(sequences[0])} amino acids, while '\n",
    "        f'the maximum for the monomer model is {MAX_MONOMER_MODEL_LENGTH}. You may '\n",
    "        'be able to run this sequence with the multimer model by selecting the '\n",
    "        'use_multimer_model_for_monomers checkbox above.')\n",
    "    \n",
    "if total_sequence_length > MAX_VALIDATED_LENGTH:\n",
    "  print('WARNING: The accuracy of the system has not been fully validated '\n",
    "        'above 3000 residues, and you may experience long running times or '\n",
    "        f'run out of memory. Total sequence length is {total_sequence_length} '\n",
    "        'residues.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search against genetic databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "from concurrent import futures\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from urllib import request\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import py3Dmol\n",
    "\n",
    "from alphafold.model import model\n",
    "from alphafold.model import config\n",
    "from alphafold.model import data\n",
    "\n",
    "from alphafold.data import feature_processing\n",
    "from alphafold.data import msa_pairing\n",
    "from alphafold.data import pipeline\n",
    "from alphafold.data import pipeline_multimer\n",
    "from alphafold.data.tools import jackhmmer\n",
    "\n",
    "from alphafold.common import protein\n",
    "\n",
    "from alphafold.relax import relax\n",
    "from alphafold.relax import utils\n",
    "\n",
    "from IPython import display\n",
    "from ipywidgets import GridspecLayout\n",
    "from ipywidgets import Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color bands for visualizing plddt\n",
    "PLDDT_BANDS = [(0, 50, '#FF7D45'),\n",
    "               (50, 70, '#FFDB13'),\n",
    "               (70, 90, '#65CBF3'),\n",
    "               (90, 100, '#0053D6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "JACKHMMER_BINARY_PATH = '/home/xiaopeng/Desktop/Prot_struct/Prot_struct_pred/ref_works/alphafold/env/bin/jackhmmer'\n",
    "DB_ROOT_PATH = f'/home/xiaopeng/Desktop/Prot_struct/Prot_struct_pred/ref_works/alphafold/seq_dbs/'\n",
    "\n",
    "# The z_value is the number of sequences in a database.\n",
    "MSA_DATABASES = [\n",
    "    # {'db_name': 'uniref100',\n",
    "    #  'db_path': f'{DB_ROOT_PATH}uniref100.fasta',\n",
    "    #  'num_streamed_chunks': 1,\n",
    "    #  'z_value': 144_113_457},\n",
    "    {'db_name': 'smallbfd',\n",
    "     'db_path': f'{DB_ROOT_PATH}bfd-first_non_consensus_sequences.fasta',\n",
    "     'num_streamed_chunks': 1,\n",
    "     'z_value': 65_984_053},\n",
    "    {'db_name': 'mgnify',\n",
    "     'db_path': f'{DB_ROOT_PATH}mgy_clusters_2022_05.fa',\n",
    "     'num_streamed_chunks': 1,\n",
    "     'z_value': 623_796_864},\n",
    "]\n",
    "\n",
    "# Search UniProt and construct the all_seq features only for heteromers, not homomers.\n",
    "if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
    "  MSA_DATABASES.extend([\n",
    "      # Swiss-Prot and TrEMBL are concatenated together as UniProt.\n",
    "      {'db_name': 'uniprot',\n",
    "       'db_path': f'{DB_ROOT_PATH}uniprot.fasta',\n",
    "       'num_streamed_chunks': 101,\n",
    "       'z_value': 225_013_025 + 565_928},\n",
    "  ])\n",
    "\n",
    "TOTAL_JACKHMMER_CHUNKS = sum([cfg['num_streamed_chunks'] for cfg in MSA_DATABASES])\n",
    "\n",
    "MAX_HITS = {\n",
    "    'uniref90': 10_000,\n",
    "    'smallbfd': 5_000,\n",
    "    'mgnify': 501,\n",
    "    'uniprot': 50_000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
    "\n",
    "def get_msa(sequences):\n",
    "  \"\"\"Searches for MSA for given sequences using chunked Jackhmmer search.\n",
    "  \n",
    "  Args:\n",
    "    sequences: A list of sequences to search against all databases.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary mapping unique sequences to dicionaries mapping each database\n",
    "    to a list of  results, one for each chunk of the database.\n",
    "  \"\"\"\n",
    "  sequence_to_fasta_path = {}\n",
    "  # Deduplicate to not do redundant work for multiple copies of the same chain in homomers.\n",
    "  for sequence_index, sequence in enumerate(sorted(set(sequences)), 1):\n",
    "    fasta_path = f'target_{sequence_index:02d}.fasta'\n",
    "    with open(fasta_path, 'wt') as f:\n",
    "      f.write(f'>query\\n{sequence}')\n",
    "    sequence_to_fasta_path[sequence] = fasta_path\n",
    "\n",
    "  # Run the search against chunks of genetic databases (since the genetic\n",
    "  # databases don't fit in Colab disk).\n",
    "  raw_msa_results = {sequence: {} for sequence in sequence_to_fasta_path.keys()}\n",
    "  print('\\nGetting MSA for all sequences')\n",
    "  with tqdm.notebook.tqdm(total=TOTAL_JACKHMMER_CHUNKS, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
    "    def jackhmmer_chunk_callback(i):\n",
    "      pbar.update(n=1)\n",
    "\n",
    "    for db_config in MSA_DATABASES:\n",
    "      db_name = db_config['db_name']\n",
    "      pbar.set_description(f'Searching {db_name}')\n",
    "      jackhmmer_runner = jackhmmer.Jackhmmer(\n",
    "          binary_path=JACKHMMER_BINARY_PATH,\n",
    "          database_path=db_config['db_path'],\n",
    "          get_tblout=True,\n",
    "          # num_streamed_chunks=db_config['num_streamed_chunks'],\n",
    "          streaming_callback=jackhmmer_chunk_callback,\n",
    "          z_value=db_config['z_value'])\n",
    "      # Query all unique sequences against each chunk of the database to prevent\n",
    "      # redunantly fetching each chunk for each unique sequence.\n",
    "      results = jackhmmer_runner.query_multiple(list(sequence_to_fasta_path.values()))\n",
    "      for sequence, result_for_sequence in zip(sequence_to_fasta_path.keys(), results):\n",
    "        raw_msa_results[sequence][db_name] = result_for_sequence\n",
    "\n",
    "  return raw_msa_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting MSA for all sequences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e68c60e0c944a279f6c856b24ff5a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [elapsed: 00:00 remaining: ?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm.notebook\n",
    "\n",
    "features_for_chain = {}\n",
    "raw_msa_results_for_sequence = get_msa(sequences)\n",
    "for sequence_index, sequence in enumerate(sequences, start=1):\n",
    "  raw_msa_results = copy.deepcopy(raw_msa_results_for_sequence[sequence])\n",
    "\n",
    "  # Extract the MSAs from the Stockholm files.\n",
    "  # NB: deduplication happens later in pipeline.make_msa_features.\n",
    "  single_chain_msas = []\n",
    "  uniprot_msa = None\n",
    "  for db_name, db_results in raw_msa_results.items():\n",
    "    merged_msa = notebook_utils.merge_chunked_msa(\n",
    "        results=db_results, max_hits=MAX_HITS.get(db_name))\n",
    "    if merged_msa.sequences and db_name != 'uniprot':\n",
    "      single_chain_msas.append(merged_msa)\n",
    "      msa_size = len(set(merged_msa.sequences))\n",
    "      print(f'{msa_size} unique sequences found in {db_name} for sequence {sequence_index}')\n",
    "    elif merged_msa.sequences and db_name == 'uniprot':\n",
    "      uniprot_msa = merged_msa\n",
    "\n",
    "  notebook_utils.show_msa_info(single_chain_msas=single_chain_msas, sequence_index=sequence_index)\n",
    "\n",
    "  # Turn the raw data into model features.\n",
    "  feature_dict = {}\n",
    "  feature_dict.update(pipeline.make_sequence_features(\n",
    "      sequence=sequence, description='query', num_res=len(sequence)))\n",
    "  feature_dict.update(pipeline.make_msa_features(msas=single_chain_msas))\n",
    "  # We don't use templates in AlphaFold Colab notebook, add only empty placeholder features.\n",
    "  feature_dict.update(notebook_utils.empty_placeholder_template_features(\n",
    "      num_templates=0, num_res=len(sequence)))\n",
    "\n",
    "  # Construct the all_seq features only for heteromers, not homomers.\n",
    "  if model_type_to_use == ModelType.MULTIMER and len(set(sequences)) > 1:\n",
    "    valid_feats = msa_pairing.MSA_FEATURES + (\n",
    "        'msa_species_identifiers',\n",
    "    )\n",
    "    all_seq_features = {\n",
    "        f'{k}_all_seq': v for k, v in pipeline.make_msa_features([uniprot_msa]).items()\n",
    "        if k in valid_feats}\n",
    "    feature_dict.update(all_seq_features)\n",
    "\n",
    "  features_for_chain[protein.PDB_CHAIN_IDS[sequence_index - 1]] = feature_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
